
# The Impact of Attention

This repository contains functionality and documentation of an experiment intended to give evidence that attention mechanisms can improve the performance of LSTM-based deep-learning models.

The documentation of the experiment can be found at https://paul-tqh-nguyen.github.io/impact_of_attention/

We compared vanilla LSTMs to LSTMs with attention (we focused on [Zhouhan Lin's self-attention mechanism](https://arxiv.org/abs/1703.03130)) on the [IMDB binary sentiment classification dataset](http://ai.stanford.edu/~amaas/data/sentiment/).

The deep learning, NLP, and data processing utilities used included:
* [Pytorch](https://pytorch.org/](https://pytorch.org/)
* [TorchText](https://torchtext.readthedocs.io/en/latest/data.html](https://torchtext.readthedocs.io/en/latest/data.html)
* [Spacy](https://spacy.io/](https://spacy.io/)
* [Pandas](https://pandas.pydata.org/](https://pandas.pydata.org/)

Visualizations utilities used included:
* [D3.js](https://d3js.org/)
* [Matplotlib](https://matplotlib.org/3.2.1/tutorials/introductory/images.html](https://matplotlib.org/3.2.1/tutorials/introductory/images.html)

We also used [json](https://docs.python.org/3/library/json.html), [os](https://docs.python.org/3/library/os.html), [sys](https://docs.python.org/3/library/sys.html), [collections](https://docs.python.org/3/library/collections.html), [contextlib](https://docs.python.org/3/library/contextlib.html), [itertools](https://docs.python.org/3/library/itertools.html), [argparse](https://docs.python.org/3/library/argparse.html), [io](https://docs.python.org/3/library/io.html), [os](https://docs.python.org/3/library/os.html), and [random](https://docs.python.org/3/library/random.html).