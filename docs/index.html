<!DOCTYPE html>
<html>
  <head>
    <title>The Impact of Attention</title>
    <link rel="stylesheet" type="text/css" href="./index.css">
    <script src="https://d3js.org/d3.v5.js"></script>
  </head>
  <body>
    <header class="stone-background">
      <div class="vertical-padding">
	<h1 style="">The Impact of Attention</h1>
	<p>A demonstration of how attention mechanisms can improve the accuracy of RNN architectures.</p>
      </div>
    </header>
    <section id="introduction">
      <div class="horizontal-padding vertical-padding">
	<h3>The Leaky Neural Network Abstraction Fallacy</h3>
	<p>A colleague from one of my reading groups asked, "Since an LSTM has memory, can't it simply remember which word vectors are important and encode important parts of vectors worth paying attention to in its hidden state? It doesn't seem practical for us to be learning about attention mechanisms if an LSTM could simply learn the correct function to weed out unimportant information. We'd be wasting time learning a technique that doesn't add anything."</p>
	<p>As <a target="_blank" href="https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b#:~:text=%3E%20The%20problem%20with%20Backpropagation%20is,them%20work%E2%80%9D%20on%20your%20data.">Andrej Karpathy</a> states, "Backpropagation is a <a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/" target="_blank">leaky abstraction</a>... If you try to ignore how it works under the hood because 'TensorFlow automagically makes my networks learn', you will not be ready to wrestle with the dangers it presents, and you will be much less effective at building and debugging neural networks."</p>
	<p>My colleague makes the exact mistake that <a target="_blank" href="https://cs.stanford.edu/people/karpathy/">Andrej Karpathy</a> points to by believing that an LSTM can magically learn the exact parameters necessary to get the best results possible.</p>
	<p>For a theoretical explanation of why my colleague's assumptions are flawed or how attention mechanism work, there are many resources elsewhere that cover this (e.g. <a target="_blank" href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html">here</a>), so I won't repeat what's already been said.</p>
	<p>Instead, I'll provide evidence against the claim that an LSTM can implicitly learn how to perform attention (and thus attention mechanisms don't contribute anything to an LSTM) by showing empirical evidence that an LSTM with an explicit attention mechanism can outperform a vanilla LSTM in terms of loss minimization, loss minimization per parameter (i.e. the LSTM models with attention can achieve smaller loss with fewer parameters than vanilla LSTMs), and time to convergence.</p>
	<p>The source code for the models we'll discuss can be found <a target="_blank" href="https://github.com/paul-tqh-nguyen/impact_of_attention">here</a>.</p>
      </div>
    </section>
    <section id="experiment-overview" class="stone-background">
      <div class="horizontal-padding vertical-padding">
	<h3>Experiment Overview</h3>
	<p>We're going to compare the performance of two types of deep learning architectures, a vanilla LSTM architecture and an LSTM architecture with attention, on the <a target="_blank" href="http://ai.stanford.edu/~amaas/data/sentiment/">IMDB dataset</a> for binary sentiment prediction.</p>
	<p>Our vanilla LSTM models will have a word embedding layer, LSTM layers, and a fully connected layer. Dropout is applied after embedding and each LSTM layer.</p>
	<p>Here's a depiction of our vanilla LSTM architecture.</p>
	<div class="architecture-depiction-container svg-container-center">
	  <svg id="vanilla-depiction"></svg>
	</div>
	<p>Our LSTM with attention models will have a word embedding layer, LSTM layers, a self-attention layer, and a fully connected layer. We're going to use <a target="_blank" href="https://arxiv.org/abs/1703.03130">Zhouhan Lin's self-attention mechanism</a>. Dropout is applied after embedding and each LSTM layer.</p>
	<p>Here's a depiction of our LSTM architecture with attention.</p>
	<div class="architecture-depiction-container svg-container-center">
	  <svg id="attention-depiction"></svg>
	</div>
	<script src="architecture_depiction.js"></script>
	<p>The dataset contains 25,000 examples for training/validation and 25,000 examples for testing.</p>
	<p>A 70/30 split of the training examples will be used for training and validation.</p>
	<p>We'll perform a grid search over the hyperparameter space of both architectures and compare the testing set loss. We'll use the validation dataset to compare training time until convergence.</p>
	<p style="padding-bottom: 0px;">The hyperparameter space of the vanilla LSTM models are described by the following:</p>
	<ul>
	  <li>Choices for Batch Size: [32]</li>
	  <li>Choices for Max Vocab Size: [25,000, 50,000]</li>
	  <li>Choices for Word Embedding:
	    <table id="word-embedding-choice-table" style="">
	      <tr>
		<td><a href="https://nlp.stanford.edu/projects/glove/">glove.6B.50d</a></td>
		<td><a href="https://nlp.stanford.edu/projects/glove/">glove.twitter.27B.25d</a></td>
		<td><a href="https://nlp.stanford.edu/projects/glove/">glove.42B.300d</a></td>
		<td><a href="https://fasttext.cc/docs/en/pretrained-vectors.html">fasttext.en.300d</a></td>
		<td><a href="https://github.com/hassyGo/charNgram2vec">charngram.100d</a></td>
	      </tr>
	      <tr>
		<td><a href="https://nlp.stanford.edu/projects/glove/">glove.6B.100d</a></td>
		<td><a href="https://nlp.stanford.edu/projects/glove/">glove.twitter.27B.50d</a></td>
		<td><a href="https://nlp.stanford.edu/projects/glove/">glove.840B.300d</a></td>
		<td><a href="https://fasttext.cc/docs/en/pretrained-vectors.html">fasttext.simple.300d</a></td>
	      </tr>
	      <tr>
		<td><a href="https://nlp.stanford.edu/projects/glove/">glove.6B.200d</a></td>
		<td><a href="https://nlp.stanford.edu/projects/glove/">glove.twitter.27B.100d</a></td>
	      </tr>
	      <tr>
		<td><a href="https://nlp.stanford.edu/projects/glove/">glove.6B.300d</a></td>
		<td><a href="https://nlp.stanford.edu/projects/glove/">glove.twitter.27B.200d</a></td>
	      </tr>
	    </table>
	  </li>
	  <li>Choices for Number of LSTM Layers: [1, 2]</li>
	  <li>Choices for Dropout Probability: [0.0, 0.25, 0.5]</li>
	</ul>
	<p style="padding-bottom: 0px;">The hyperparameter space of the LSTM models with are the same as those for the vanilla LSTM models in addition to the following:</p>
	<ul>
	  <li>Choices for Attention Head Count: [1, 2, 32]</li>
	  <li>Choices for Attention Intermediate Size: [8, 32]</li>
	</ul>
	<p>We'll be using binary cross entropy loss and the Adam optimizer.</p>
      </div>
    </section>
    <section id="experiment-results">
      <div class="horizontal-padding vertical-padding">
	<h3>Experiment Results</h3>
	<p>Below, we'll compare the vanilla LSTM architecture to the LSTM with attention architecture w.r.t. loss minimization, loss minimization per parameter, and training time until convergence.</p>
	<p>There were 468 possible hyperparameter combinations for the vanilla LSTM architecture.</p>
	<p>There were 2808 possible hyperparameter combinations for the LSTM with attention architecture (there were more hyperparameter options for the LSTM with attention models).</p>
	<p>We completed an exhaustive search over all the possible hyperparameter combinations.</p>
	<p>The first result to note is that the hyperparameter search space for the LSTM with attention architecture is much larger. Thus, grid search will take much longer and there are many possibly bad hyperparameter selections to weed out. In practice, I've found that discovering a well-performing hyperparameter selection did not require an exhaustive search and yielded the benefits to be discussed below.</p>
	<p>Here are the 10 best models for each architecture.</p>
	<div id="bar-chart" class="svg-container-center">
	  <svg id="bar-chart-svg"></svg>
	  <script src="bar_chart.js"></script>
	</div>
	<p>Note the scale of the y-axis.</p>
	<p>The best LSTM with attention models outperform the best vanilla LSTM models consistenly by a binary cross-entropy score difference of 0.02.</p>
	<p>We'll next compare the LSTM with attention models to the vanilla LSTM models based on loss minimization per parameter. In particular, we'll analyze loss vs parameter count for each model evaluated.</p>
	<div id="scatter-plot" class="svg-container-center">
	  <svg id="scatter-plot-svg"></svg>
	  <script src="scatter_plot.js"></script>
	</div>
	<p>Notice that the LSTM with attention models (even when they have fewer parameters than the vanilla LSTM models) consistently achieve a smaller loss.</p>
	<p>NB: Each of the vertically elongated clusters in the scatter plot above are clusters of models with the same number of LSTM layers. The noticeable hotizontal distances between these vertically elongated clusters are due to the large number of parameters required to add a single LSTM layer.</p>
	<p>We'll next compare the training time necessary until convergence for the models.</p>
	<div id="line-graph" class="svg-container-center">
	  <svg id="line-graph-svg"></svg>
	  <script src="line_graph.js"></script>
	</div>
	<p>When using deep learning models in practice, we aim to avoid overfitting. One method of doing that is to use a validation dataset. We know when our model has started to overfit to the training data when the validation stops decreasing or even starts increasing. The parameter values for a model are chosen based on the validation score since the validation examples are not seen during training.</p>
	<p>We can measure how quickly a model converges by counting the number of epochs a model takes to reach it's minimum validation loss.</p>
	<p>The graph above shows the validation score over time for the 10 best LSTM with attention models and the 10 best vanilla LSTM models.</p>
	<p>Though the best LSTM with attention models only outperform  the best vanilla LSTM models by a small difference of 0.02 in terms of binary cross entropy loss, the best LSTM with attention models converge significantly more quickly than the best vanilla LSTM models. We can see in the line graph above that the LSTM with attention models get very close to their minimum validation scores after 1 epoch while doing the same for the vanilla LSTM models takes more than 3 epochs.</p>
      </div>
    </section>
    <section id="conclusion" class="stone-background">
      <div class="horizontal-padding vertical-padding">
	<h3>Concluding Remarks</h3>
	<p>To expand on <a target="_blank" href="https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b#:~:text=%3E%20The%20problem%20with%20Backpropagation%20is,them%20work%E2%80%9D%20on%20your%20data.">Andrej Karpathy</a>'s point, I will emphasize that it is inadvisable to gloss over the details of how deep-learning models work on non-synthetic use cases. It is insufficient to merely memorize the vague descriptions of what deep-learning models can do. As shown here, doing so will lead to an inaccurate understanding of what certain architectures are and are not capapble of.</p>
	<p>We've shown that attention mechanisms, though seemingly redundant, can yield better results in practice.</p>
	<p>Hopefully, the work here does not solely convey on the benefits of attention but also conveys the importance of practical experience. Learning through experimentation and practice yield far superior results to textbook study alone.</p>
      </div>
      <table style="table-layout: fixed; width: 100%; padding-top: 40px; padding-bottom: 40px;">
	<tr>
	  <td style="width:10%;"></td>
	  <td style="width:30%;">
      	    <card class="stone-background">
      	      <a target="_blank" href="https://github.com/paul-tqh-nguyen">
      		<div class="card-text">
      		  <p>Interested in my work?</p>
      		  <p><b>See my projects on GitHub.</b></p>
      		</div>
      	      </a>
      	    </card>
	  </td>
	  <td style="width:20%;"></td>
	  <td style="width:30%;">
      	    <card class="stone-background">
      	      <a target="_blank" href="https://paul-tqh-nguyen.github.io/about/">
      		<div class="card-text">
      		  <p>Want to learn more about me?</p>
      		  <p><b>Visit my website.</b></p>
      		</div>
      	      </a>
      	    </card>
	  </td>
	  <td style="width:10%;"></td>
	</tr>
      </table>
    </section>
  </body>
</html>
