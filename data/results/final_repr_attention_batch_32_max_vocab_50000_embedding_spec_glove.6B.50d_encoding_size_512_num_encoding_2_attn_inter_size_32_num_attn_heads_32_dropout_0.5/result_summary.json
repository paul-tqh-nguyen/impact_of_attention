{"number_of_epochs": 5, "batch_size": 32, "vocab_size": 50002, "pre_trained_embedding_specification": "glove.6B.50d", "encoding_hidden_size": 512, "number_of_encoding_layers": 2, "attention_intermediate_size": 32, "number_of_attention_heads": 32, "dropout_probability": 0.5, "final_representation": "attention", "best_training_accuracy": 0.84375, "best_training_accuracy_epoch": 2.8190127970749543, "best_training_loss": 1.0288686752319336, "best_training_loss_epoch": 4.23400365630713, "best_validation_accuracy": 0.530097517815042, "best_validation_accuracy_epoch": 1.0, "best_validation_loss": 0.7831639997502591, "best_validation_loss_epoch": 1.0, "test_loss": 0.7884461296260205, "test_accuracy": 0.5248161764705882, "number_of_parameters": 11209286, "training_number_epochs_to_within_three_percent_of_max_accuracy": 2.8190127970749543, "training_number_epochs_to_within_five_percent_of_max_accuracy": 2.8190127970749543, "training_number_epochs_to_within_ten_percent_of_max_accuracy": 0.08226691042047532, "validation_number_epochs_to_within_three_percent_of_max_accuracy": 1.0, "validation_number_epochs_to_within_five_percent_of_max_accuracy": 1.0, "validation_number_epochs_to_within_ten_percent_of_max_accuracy": 1.0}