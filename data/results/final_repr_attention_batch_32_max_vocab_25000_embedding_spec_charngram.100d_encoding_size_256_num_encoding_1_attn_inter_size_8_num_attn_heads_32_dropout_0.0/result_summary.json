{"number_of_epochs": 5, "batch_size": 32, "vocab_size": 25002, "pre_trained_embedding_specification": "charngram.100d", "encoding_hidden_size": 256, "number_of_encoding_layers": 1, "attention_intermediate_size": 8, "number_of_attention_heads": 32, "dropout_probability": 0.0, "final_representation": "attention", "best_training_accuracy": 1.0, "best_training_accuracy_epoch": 0.6197440585009141, "best_training_loss": 0.7580721378326416, "best_training_loss_epoch": 0.051188299817184646, "best_validation_accuracy": 0.8863031914893617, "best_validation_accuracy_epoch": 4.0, "best_validation_loss": 0.4274134554761521, "best_validation_loss_epoch": 1.0, "test_loss": 0.43692565692202817, "test_accuracy": 0.8704843350383632, "number_of_parameters": 3270546, "training_number_epochs_to_within_three_percent_of_max_accuracy": 0.6197440585009141, "training_number_epochs_to_within_five_percent_of_max_accuracy": 0.360146252285192, "training_number_epochs_to_within_ten_percent_of_max_accuracy": 0.23217550274223034, "validation_number_epochs_to_within_three_percent_of_max_accuracy": 1.0, "validation_number_epochs_to_within_five_percent_of_max_accuracy": 1.0, "validation_number_epochs_to_within_ten_percent_of_max_accuracy": 1.0}