{"number_of_epochs": 5, "batch_size": 32, "vocab_size": 50002, "pre_trained_embedding_specification": "charngram.100d", "encoding_hidden_size": 512, "number_of_encoding_layers": 1, "attention_intermediate_size": 32, "number_of_attention_heads": 1, "dropout_probability": 0.25, "final_representation": "attention", "best_training_accuracy": 0.9375, "best_training_accuracy_epoch": 3.170018281535649, "best_training_loss": 1.2193931341171265, "best_training_loss_epoch": 1.6343692870201096, "best_validation_accuracy": 0.7514184398854032, "best_validation_accuracy_epoch": 5.0, "best_validation_loss": 0.7330753283297762, "best_validation_loss_epoch": 1.0, "test_loss": 0.5482500727905337, "test_accuracy": 0.7500399616368286, "number_of_parameters": 7550027, "training_number_epochs_to_within_three_percent_of_max_accuracy": 3.170018281535649, "training_number_epochs_to_within_five_percent_of_max_accuracy": 2.9853747714808043, "training_number_epochs_to_within_ten_percent_of_max_accuracy": 0.2760511882998172, "validation_number_epochs_to_within_three_percent_of_max_accuracy": 5.0, "validation_number_epochs_to_within_five_percent_of_max_accuracy": 4.0, "validation_number_epochs_to_within_ten_percent_of_max_accuracy": 4.0}